function [Y,Xf,Af] = siec2(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 17-Jun-2017 13:37:08.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timsteps
%   Each X{1,ts} = 16xQ matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 2xQ matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1_xoffset = [30;0;0;55;17;1;9;1;4;-30;-30;21;0;-388;40;18];
x1_step1_gain = [0.0289855072463768;0.00615384615384615;0.1;0.0714285714285714;0.0434782608695652;0.0137931034482759;0.0689655172413793;0.0227272727272727;0.181818181818182;0.0294117647058824;0.0285714285714286;0.00264200792602378;0.0444444444444444;0.00518806744487678;0.025;0.0833333333333333];
x1_step1_ymin = -1;

% Layer 1
b1 = [1.7070199676208897;1.1705755180163429;-0.84553713521774443;0.063030920657641487;-0.20428090350111636;-0.082084940833438355;-1.036570877931744;1.2302445002326989;1.4185500760733871];
IW1_1 = [-0.35122015714879107 0.30087415074548679 0.43117982276990302 -0.47639841235532704 0.13950265056218203 0.39366631718011752 0.31366012805319282 -0.092222811222885087 0.20858203835327316 0.24229216353942956 -0.68649094380525411 0.4749745486089173 -0.21693176350586679 -0.6490537549023192 0.27611756229047912 -0.44158866507990779;-0.46913364857411982 -0.23247564722150782 0.6178292704208771 -0.45635020198909171 0.14711076680866755 -0.79809472537727544 -0.20467600140701209 -0.0073244127438794101 0.70892043955947426 0.40283759081964249 0.2030766274420833 -0.11894696837637014 -0.53183206575938302 0.047066007500652769 -0.42341442845121263 -0.079210190080732212;0.070823359320650509 0.27356110209538248 0.50710128575000923 -0.33504094390332861 -0.52640106837023481 -0.15572635819629943 -0.26441256390039752 -0.17395333535160054 -0.50944528324249105 -0.32602929855630014 0.42274393589556425 0.67126559426969912 0.43977578293604508 0.5222683793251458 -0.048713707274112963 0.48221679496534586;-0.36312437694716437 0.36070716810076792 0.80617776098269323 1.0750415772234758 0.31484679126259191 -0.40501405747085945 0.64011838840407576 -0.29339651622853402 0.25289277411947259 -0.38918003165557308 0.47896951607160965 -0.017679325376268748 0.39673409393733272 0.36519751488361757 0.21462711527331427 0.5141006374282826;-0.40984495611932004 1.1079442142591915 0.15419803264940329 1.0593725196903514 0.20857226393650727 -0.24628975753386456 0.82890141423138242 -0.099754340949725684 0.75251804041195713 0.41618861148840924 0.27613932934841473 -0.57667658525520249 0.96141292241630061 1.1591442896426363 0.81789174373945928 0.31789720279360251;-0.44983396678891624 -0.87925509031591376 -0.23790992787235615 -0.34869210536393924 0.46586071220313918 -0.45696630109728537 -0.25989808071855719 0.15691853019075119 -0.69584710548761775 0.34700845651704521 0.3048685610429086 0.27084905901352108 -0.13858218456432109 0.12334636491593656 -0.65859615847949382 0.073570424589066541;-0.35074954868100189 1.2062473588864673 0.79103021271897689 1.3380029518838741 -0.82235104501099365 0.16645690760048076 0.02477280464566774 0.81685858005985934 1.5222434978567847 0.16968796994096408 0.49192137486846677 -1.6812565447500394 0.74602860514897895 1.065735603455247 0.86580772356626878 -0.2297538501532555;0.35007614732139286 -0.312707200728498 -0.31309671691609781 0.39365329152187273 -0.07020045365891539 -0.54489205879455238 -0.089404218432060797 -0.15368092111483991 -0.30142908339228458 0.73384798708887389 -0.0012993933303464709 0.11086529730757112 0.53872217923170462 0.46500943883990775 -0.44345601611571683 0.62382572444717277;0.62810642078322698 0.43665832947628325 0.68267655043810449 0.0035023709305041159 0.18821522612523189 -0.10923877979117159 0.59996870674960401 0.7529259541003569 0.27312943468133871 -0.5549762351314893 -0.35173829001506762 -0.66927476106477912 0.029462374048893698 0.15371229452071253 0.60158254675181611 0.1209716099440393];

% Layer 2
b2 = [-0.47181550741693246;-0.25937421028153956];
LW2_1 = [-0.0741283923947271 -1.0395213806980765 -0.54934089896284288 1.1771207331148676 1.6217486718624394 -0.77104813361716851 2.3177747755763773 0.93416150525124342 -0.29654865425473442;0.71872889103941928 -0.60307625810427767 -0.42998949302781803 -0.39951832248117958 -1.7385829187697686 0.59143128446816073 -2.6443225223077507 0.96691071673605022 -1.2397004587156444];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX, X = {X}; end;

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},2); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1_gain,x1_step1_xoffset,x1_step1_ymin);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX, Y = cell2mat(Y); end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings_gain,settings_xoffset,settings_ymin)
y = bsxfun(@minus,x,settings_xoffset);
y = bsxfun(@times,y,settings_gain);
y = bsxfun(@plus,y,settings_ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numer = exp(n);
denom = sum(numer,1);
denom(denom == 0) = 1;
a = bsxfun(@rdivide,numer,denom);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
